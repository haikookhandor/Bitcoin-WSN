{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining reputation in social network\n",
    "Efforts by:\n",
    "1. Haikoo Khandor 20110071\n",
    "2. Madhav Kanda   20110104\n",
    "3. Dhruv Patel    20110129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from correlation import c_clustering\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "from fairness_goodness_computation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "Data = open(\"soc-sign-bitcoinotc.csv\", \"r\")\n",
    "next(Data, None)  # skip the headers\n",
    "graph_type = nx.DiGraph() # Directed Graph\n",
    "df = pd.read_csv(\"soc-sign-bitcoinotc.csv\") # Reading the data\n",
    "df = df.sort_values(by=\"Timestamp\") # Sorting the data based on the timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Weight /= 10 # Reducing weights to -1 to 1 range:\n",
    "df.Weight = (df.Weight - df.Weight.mean())  # Normalizing the weights\n",
    "print(df.head())\n",
    "split = int(len(df) / 8)  # Using first 12.5% data for initial graph\n",
    "train = df.iloc[:split, :]\n",
    "test = df.iloc[split:, :]\n",
    "G = nx.from_pandas_edgelist(\n",
    "    train, source=\"Source\", target=\"Target\", edge_attr=\"Weight\", create_using=graph_type\n",
    ") # Creating the initial graph\n",
    "H = G.copy() # Creating a copy of the initial graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(nx.info(H)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computing Fairness and Goodness\n",
    "fairness, goodness = compute_fairness_goodness(H) \n",
    "# Setting node attributes\n",
    "nx.set_node_attributes(H, fairness, \"fairness\") \n",
    "nx.set_node_attributes(H, goodness, \"goodness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Co-relation Clustering\n",
    "CC = c_clustering(H.copy(), delta=1 / 180, complete_graph=True) # Computing the co-relation clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = CC.run() # Running the co-relation clustering\n",
    "print(len(clusters)) # Printing the number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dict(zip(range(len(clusters)), clusters)) # Creating a dictionary of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_graph = True # Setting the complete graph parameter to True\n",
    "weights = nx.get_edge_attributes(H, \"Weight\")\n",
    "in_p = defaultdict(int) # Initializing the parameters\n",
    "out_p = defaultdict(int)\n",
    "in_n = defaultdict(int)\n",
    "out_n = defaultdict(int)\n",
    "N_in_p = defaultdict(int)\n",
    "N_out_p = defaultdict(int)\n",
    "N_in_n = defaultdict(int)\n",
    "N_out_n = defaultdict(int)\n",
    "preds = {}\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    for u in clusters[i]: \n",
    "        for v in H.neighbors(u):\n",
    "            if v in clusters[i]:\n",
    "                if weights[(u, v)] > 0: \n",
    "                    in_p[i] += weights[(u, v)]\n",
    "                    N_in_p[i] += 1\n",
    "                else:\n",
    "                    in_n[i] += weights[(u, v)]\n",
    "                    N_in_n[i] += 1\n",
    "            else:\n",
    "                if weights[(u, v)] > 0:\n",
    "                    out_p[i] += weights[(u, v)]\n",
    "                    N_out_p[i] += 1\n",
    "                else:\n",
    "                    out_n[i] += weights[(u, v)]\n",
    "                    N_out_n[i] += 1\n",
    "                    \n",
    "        if complete_graph: # complete incomplete graph by weight prediction using fairness-goodness\n",
    "            for v in nx.non_neighbors(H, u): \n",
    "                if v in clusters[i]:\n",
    "                    if fairness[u] * goodness[v] > 0:\n",
    "                        in_p[i] += fairness[u] * goodness[v]\n",
    "                        preds[(u, v)] = fairness[u] * goodness[v]\n",
    "                        N_in_p[i] += 1\n",
    "                    else:\n",
    "                        in_n[i] += fairness[u] * goodness[v]\n",
    "                        preds[(u, v)] = fairness[u] * goodness[v]\n",
    "                        N_in_n[i] += 1\n",
    "                else:\n",
    "                    if fairness[u] * goodness[v] > 0:\n",
    "                        out_p[i] += fairness[u] * goodness[v]\n",
    "                        preds[(u, v)] = fairness[u] * goodness[v]\n",
    "                        N_out_p[i] += 1\n",
    "                    else:\n",
    "                        out_n[i] += fairness[u] * goodness[v]\n",
    "                        preds[(u, v)] = fairness[u] * goodness[v]\n",
    "                        N_out_n[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(N_in_p)\n",
    "print(N_in_n)\n",
    "print(N_out_p)\n",
    "print(N_out_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_f = 0.95\n",
    "threshold_g = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_node = {i: 1 if fairness[i] > threshold_f else 0 for i in H.nodes}\n",
    "good_node = {i: 1 if goodness[i] > threshold_g else 0 for i in H.nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fair_node length: \", len(fair_node))\n",
    "print(\"good_node length: \", len(good_node))\n",
    "print(\"fairness length: \", len(fairness))\n",
    "print(\"goodness length: \", len(goodness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_g = []\n",
    "for i in range(len(clusters)):\n",
    "    trusty_of_clusters = 0\n",
    "    for u in H.nodes - clusters[i]:\n",
    "        for j in H.neighbors(u):\n",
    "            if j in clusters[i]:\n",
    "                if (u, j) in weights.keys():\n",
    "                    trusty_of_clusters += weights[(u, j)] * fair_node[u] * fairness[u]\n",
    "\n",
    "    for v in clusters[i]:\n",
    "        trusty_of_clusters += goodness[v] * good_node[v]\n",
    "\n",
    "    trusty_of_clusters = trusty_of_clusters / (len(clusters[i]))\n",
    "    metrics_g.append(trusty_of_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    zip(\n",
    "        range(len(clusters)),\n",
    "        [len(clusters[i]) for i in range(len(clusters))],\n",
    "        [N_in_p[i] for i in range(len(clusters))],\n",
    "        [N_out_n[i] for i in range(len(clusters))],\n",
    "        metrics_g,\n",
    "    )\n",
    ").sort_values(by=4, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_add = H.copy() # Creating a copy of the initial graph for adding nodes and edges\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(200):\n",
    "    new_node = max(list(H.nodes)) + j + 1\n",
    "    for i in range(len(clusters)):\n",
    "        node = np.random.choice(list(clusters[i]), 1, replace=True).item()\n",
    "        weight = np.random.choice([-1,1])\n",
    "        H_add.add_edge(new_node, node, Weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.info(H_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness, goodness = compute_fairness_goodness(H_add)\n",
    "nx.set_node_attributes(H_add, fairness, \"fairness\")\n",
    "nx.set_node_attributes(H_add, goodness, \"goodness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_graph = True\n",
    "weights = nx.get_edge_attributes(H, \"Weight\")\n",
    "# initialize the metrics\n",
    "in_p = defaultdict(int)\n",
    "out_p = defaultdict(int)\n",
    "in_n = defaultdict(int)\n",
    "out_n = defaultdict(int)\n",
    "N_in_p = defaultdict(int)\n",
    "N_out_p = defaultdict(int)\n",
    "N_in_n = defaultdict(int)\n",
    "N_out_n = defaultdict(int)\n",
    "\n",
    "preds_new = {}\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    for u in clusters[i]:\n",
    "        for v in H.neighbors(u):\n",
    "            if v in clusters[i]:\n",
    "                if weights[(u, v)] > 0:\n",
    "                    in_p[i] += weights[(u, v)]\n",
    "                    N_in_p[i] += 1\n",
    "                else:\n",
    "                    in_n[i] += weights[(u, v)]\n",
    "                    N_in_n[i] += 1\n",
    "            else:\n",
    "                if weights[(u, v)] > 0:\n",
    "                    out_p[i] += weights[(u, v)]\n",
    "                    N_out_p[i] += 1\n",
    "                else:\n",
    "                    out_n[i] += weights[(u, v)]\n",
    "                    N_out_n[i] += 1\n",
    "        if complete_graph: # If the graph is complete, we need to add the edges between the nodes that are not neighbors\n",
    "            for v in nx.non_neighbors(H, u):\n",
    "                if v in clusters[i]:\n",
    "                    if fairness[u] * goodness[v] > 0:\n",
    "                        in_p[i] += fairness[u] * goodness[v]\n",
    "                        preds_new[(u, v)] = fairness[u] * goodness[v]\n",
    "                        N_in_p[i] += 1\n",
    "                    else:\n",
    "                        in_n[i] += fairness[u] * goodness[v]\n",
    "                        preds_new[(u, v)] = fairness[u] * goodness[v]\n",
    "                        N_in_n[i] += 1\n",
    "                else:\n",
    "                    if fairness[u] * goodness[v] > 0:\n",
    "                        out_p[i] += fairness[u] * goodness[v]\n",
    "                        preds_new[(u, v)] = fairness[u] * goodness[v]\n",
    "                        N_out_p[i] += 1\n",
    "                    else:\n",
    "                        out_n[i] += fairness[u] * goodness[v]\n",
    "                        preds_new[(u, v)] = fairness[u] * goodness[v]\n",
    "                        N_out_n[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_f = []\n",
    "for i in range(len(clusters)):\n",
    "    trusty_of_clusters = 0\n",
    "    for u in H.nodes - clusters[i]:\n",
    "        for j in H.neighbors(u):\n",
    "            if j in clusters[i]:\n",
    "                if (u, j) in weights.keys():\n",
    "                    trusty_of_clusters += weights[(u, j)] * fair_node[u] * fairness[u]\n",
    "                    \n",
    "    for v in clusters[i]:\n",
    "        trusty_of_clusters += goodness[v] * good_node[v]\n",
    "    trusty_of_clusters = trusty_of_clusters / (len(clusters[i]))\n",
    "    metrics_f.append(trusty_of_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preds: predicted weights of missing edges <br>\n",
    "preds_new: predicted weights of missing edges after addition of new nodes/edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cluster_edges is a dictionary consisting of the predicted edges as values and keys as the clusters in which they are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_edges = {}\n",
    "for i in dic.keys():\n",
    "    nodes_in_cluster = list(dic[i])\n",
    "    for u, v in preds.keys():\n",
    "        if u in nodes_in_cluster and v in nodes_in_cluster:\n",
    "            if i not in cluster_edges.keys():\n",
    "                cluster_edges[i] = list()\n",
    "            cluster_edges[i].append(((u, v), preds[(u, v)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_new_edges = {}\n",
    "for i in dic.keys():\n",
    "    nodes_in_cluster = list(dic[i])\n",
    "    for u, v in preds_new.keys():\n",
    "        if u in nodes_in_cluster and v in nodes_in_cluster:\n",
    "            if i not in cluster_new_edges.keys():\n",
    "                cluster_new_edges[i] = list()\n",
    "            cluster_new_edges[i].append(((u, v), preds_new[(u, v)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_new_edges"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diff_in_weights_cluster is a dictionary consisting of the sum of absolute differences in predicted weights in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_in_weights_cluster = {}\n",
    "for i in range(len(clusters)):\n",
    "    diff_in_weights_cluster[i] = 0\n",
    "    if i in cluster_edges.keys() and i in cluster_new_edges.keys():\n",
    "        for j in range(len(cluster_edges[i])):\n",
    "            ((u1, v1), w1) = cluster_edges[i][j]\n",
    "            ((u2, v2), w2) = cluster_new_edges[i][j]\n",
    "            diff_in_weights_cluster[i] += abs(w1 - w2)\n",
    "        diff_in_weights_cluster[i] = diff_in_weights_cluster[i] / len(cluster_edges[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_in_weights_cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the trustworthiness of clusters vs difference in weights\n",
    "x = pd.Series(diff_in_weights_cluster)\n",
    "y = pd.Series(metrics_g)\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"Difference in weights\")\n",
    "plt.ylabel(\"Trustworthiness of clusters\")\n",
    "plt.title(\"Trustworthiness of clusters vs Difference in weights\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the trustworthiness of clusters vs difference in weights\n",
    "x = pd.Series(diff_in_weights_cluster)\n",
    "y = pd.Series(metrics_f)\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"Difference in weights\")\n",
    "plt.ylabel(\"Trustworthiness of clusters\")\n",
    "plt.title(\"Trustworthiness of clusters vs Difference in weights\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sort = sorted(metrics_f)\n",
    "m_sort"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co-relation between trustworthiness levels before and after adding the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics_g, metrics_f, \"o\")\n",
    "plt.xlabel(\"Old Trustworthiness of clusters\")\n",
    "plt.ylabel(\"New Trustworthiness of clusters\")\n",
    "plt.title(\"Correlation between old and new trustworthiness of clusters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
